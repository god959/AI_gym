{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#導入相關模組\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "\n",
    "import jieba\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#讀取jieba所需的自建辭典\n",
    "jieba.load_userdict(\"E:/Python 3.7/pyetl/Demodb0103/gym/data/dict.txt\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取要斷詞的json檔\n",
    "DATASET_DIR = 'E:/Python 3.7/pyetl/Demodb0103/gym/data/gymz.json'\n",
    "with open(DATASET_DIR, encoding='utf8') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取停止詞典\n",
    "STOP_WORDS_DIR = 'E:/Python 3.7/pyetl/Demodb0103/gym/data/stopWords.txt'\n",
    "with open(STOP_WORDS_DIR, encoding='utf8') as f:\n",
    "    stop_words = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抽出文章的標題與內容\n",
    "content_list = list(map(lambda d: d['content'], dataset))\n",
    "title_list = list(map(lambda d: d['title'], dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#替換不需要的句子，並正規化\n",
    "# start = time.clock()\n",
    "gym_list =[]\n",
    "for i in content_list:\n",
    "    i = re.sub('※ 發信站: 批踢踢實業坊',' ', i)\n",
    "    i = re.sub('※ 文章網址:',' ', i)\n",
    "    i = re.sub('※ 編輯:',' ', i)\n",
    "    i = re.sub('(臺灣)',' ', i)\n",
    "    i = re.sub('來自:',' ', i)\n",
    "    #只保留中文\n",
    "    rule = re.compile(r\"[^\\u4e00-\\u9fa5]\")\n",
    "    i = rule.sub('', i)\n",
    "    gym_list.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將文章正規化，並進行jieba斷詞\n",
    "rule = re.compile(r\"[^\\u4e00-\\u9fa5]\")\n",
    "gym_list = [list(jieba.cut(rule.sub('', speech))) for speech in gym_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##去除停止詞\n",
    "for idx, speech in enumerate(gym_list):\n",
    "    gym_list[idx] = ' '.join([word for word in speech if word not in stop_words])\n",
    "# end = time.clock()\n",
    "# print('運行時間: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2Vec\n",
    "# 資料形式為一個文檔各為list元素為字串\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#全文章轉為各list包起來\n",
    "doc_clean1 = [doc.split() for doc in gym_list]\n",
    "\n",
    "# 建立模型\n",
    "#window:CBOW下決定Word2Vec一次取多少詞來預測中間詞\n",
    "#min_count:出現次數大於等於min_count的詞，才會納入Word2Vec的詞典中\n",
    "#negative:Negative Sampling的取樣數量，5~20適合小數據，2~5適合大數據\n",
    "# worker=使用多核計算機進行更快的訓練\n",
    "model = Word2Vec(doc_clean1,window=5, negative=5,min_count=1,size=250, iter=10)\n",
    "\n",
    "# # 基於2d PCA擬合數據\n",
    "# X = model[model.wv.vocab]\n",
    "# pca = PCA(n_components=2)\n",
    "# result = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('很胖', 0.8617879152297974),\n",
       " ('很瘦', 0.8611124753952026),\n",
       " ('紙片', 0.8551267385482788),\n",
       " ('瘦子', 0.8493390679359436),\n",
       " ('胖子', 0.8449896574020386),\n",
       " ('想瘦', 0.8367601037025452),\n",
       " ('回娘家', 0.8110179305076599),\n",
       " ('下屆齡', 0.8108158111572266),\n",
       " ('瘦下', 0.810620903968811),\n",
       " ('變美', 0.8088332414627075)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#顯示指定詞的關聯詞\n",
    "model.wv.most_similar('肥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>增肌</th>\n",
       "      <th>cos</th>\n",
       "      <th>肥</th>\n",
       "      <th>cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>減脂</td>\n",
       "      <td>0.798880</td>\n",
       "      <td>很胖</td>\n",
       "      <td>0.861788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>增脂</td>\n",
       "      <td>0.784306</td>\n",
       "      <td>很瘦</td>\n",
       "      <td>0.861112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>增肌期</td>\n",
       "      <td>0.777738</td>\n",
       "      <td>紙片</td>\n",
       "      <td>0.855127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>減脂期</td>\n",
       "      <td>0.773392</td>\n",
       "      <td>瘦子</td>\n",
       "      <td>0.849339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>實施實</td>\n",
       "      <td>0.770620</td>\n",
       "      <td>胖子</td>\n",
       "      <td>0.844990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>訓外</td>\n",
       "      <td>0.769521</td>\n",
       "      <td>想瘦</td>\n",
       "      <td>0.836760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>主感謝</td>\n",
       "      <td>0.757237</td>\n",
       "      <td>回娘家</td>\n",
       "      <td>0.811018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>增肌先</td>\n",
       "      <td>0.754268</td>\n",
       "      <td>下屆齡</td>\n",
       "      <td>0.810816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>抓五個</td>\n",
       "      <td>0.734153</td>\n",
       "      <td>瘦下</td>\n",
       "      <td>0.810621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>增肌為</td>\n",
       "      <td>0.729781</td>\n",
       "      <td>變美</td>\n",
       "      <td>0.808833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    增肌       cos    肥       cos\n",
       "0   減脂  0.798880   很胖  0.861788\n",
       "1   增脂  0.784306   很瘦  0.861112\n",
       "2  增肌期  0.777738   紙片  0.855127\n",
       "3  減脂期  0.773392   瘦子  0.849339\n",
       "4  實施實  0.770620   胖子  0.844990\n",
       "5   訓外  0.769521   想瘦  0.836760\n",
       "6  主感謝  0.757237  回娘家  0.811018\n",
       "7  增肌先  0.754268  下屆齡  0.810816\n",
       "8  抓五個  0.734153   瘦下  0.810621\n",
       "9  增肌為  0.729781   變美  0.808833"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#顯示各個指定詞的關聯詞\n",
    "def most_similar(w2v_model, words, topn=10):\n",
    "    similar_df = pd.DataFrame()\n",
    "    for word in words:\n",
    "        try:\n",
    "            similar_words = pd.DataFrame(w2v_model.wv.most_similar(word, topn=topn), columns=[word, 'cos'])\n",
    "            similar_df = pd.concat([similar_df, similar_words], axis=1)\n",
    "        except:\n",
    "            print(word, \"not found in Word2Vec model!\")\n",
    "    return similar_df\n",
    "most_similar(model, ['增肌', '肥'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'word2vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-265-822b3eabbe03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'增肌'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'word2vec'"
     ]
    }
   ],
   "source": [
    "# import word2vec #需要word2vec模組\n",
    "# indexes = model.cosine(u'增肌')\n",
    "# for index in indexes[0]:\n",
    "#     print (model.vocab[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext\n",
    "from gensim.models import FastText\n",
    "model2 = FastText(doc_clean1,window=5, negative=5,min_count=1,size=250, iter=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('很瘦', 0.8827726244926453),\n",
       " ('很胖', 0.8802703619003296),\n",
       " ('紙片', 0.8683609962463379),\n",
       " ('人紙片', 0.8507423400878906),\n",
       " ('瘦子', 0.8441587090492249),\n",
       " ('胖子', 0.83818519115448),\n",
       " ('想瘦', 0.8364203572273254),\n",
       " ('瘦瘦', 0.828603982925415),\n",
       " ('臉胖要', 0.8275570273399353),\n",
       " ('變胖變', 0.8255159258842468)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#顯示指定詞的關聯詞\n",
    "model2.wv.most_similar('肥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>增肌</th>\n",
       "      <th>cos</th>\n",
       "      <th>肥</th>\n",
       "      <th>cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>增肌量</td>\n",
       "      <td>0.966287</td>\n",
       "      <td>很瘦</td>\n",
       "      <td>0.882773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>增肌菜</td>\n",
       "      <td>0.964887</td>\n",
       "      <td>很胖</td>\n",
       "      <td>0.880270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>增肌增</td>\n",
       "      <td>0.963615</td>\n",
       "      <td>紙片</td>\n",
       "      <td>0.868361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>增肌壯</td>\n",
       "      <td>0.963447</td>\n",
       "      <td>人紙片</td>\n",
       "      <td>0.850742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>增肌健</td>\n",
       "      <td>0.962881</td>\n",
       "      <td>瘦子</td>\n",
       "      <td>0.844159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>增肌消</td>\n",
       "      <td>0.962729</td>\n",
       "      <td>胖子</td>\n",
       "      <td>0.838185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>增肌當</td>\n",
       "      <td>0.962651</td>\n",
       "      <td>想瘦</td>\n",
       "      <td>0.836420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>增肌文</td>\n",
       "      <td>0.962407</td>\n",
       "      <td>瘦瘦</td>\n",
       "      <td>0.828604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>增肌臉</td>\n",
       "      <td>0.962385</td>\n",
       "      <td>臉胖要</td>\n",
       "      <td>0.827557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>增肌早</td>\n",
       "      <td>0.962175</td>\n",
       "      <td>變胖變</td>\n",
       "      <td>0.825516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    增肌       cos    肥       cos\n",
       "0  增肌量  0.966287   很瘦  0.882773\n",
       "1  增肌菜  0.964887   很胖  0.880270\n",
       "2  增肌增  0.963615   紙片  0.868361\n",
       "3  增肌壯  0.963447  人紙片  0.850742\n",
       "4  增肌健  0.962881   瘦子  0.844159\n",
       "5  增肌消  0.962729   胖子  0.838185\n",
       "6  增肌當  0.962651   想瘦  0.836420\n",
       "7  增肌文  0.962407   瘦瘦  0.828604\n",
       "8  增肌臉  0.962385  臉胖要  0.827557\n",
       "9  增肌早  0.962175  變胖變  0.825516"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#顯示各個指定詞的關聯詞\n",
    "def most_similar(fas_model, words, topn=10):\n",
    "    similar_df = pd.DataFrame()\n",
    "    for word in words:\n",
    "        try:\n",
    "            similar_words = pd.DataFrame(fas_model.wv.most_similar(word, topn=topn), columns=[word, 'cos'])\n",
    "            similar_df = pd.concat([similar_df, similar_words], axis=1)\n",
    "        except:\n",
    "            print(word, \"not found in Word2Vec model!\")\n",
    "    return similar_df\n",
    "most_similar(model2, ['增肌', '肥'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
