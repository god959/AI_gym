{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python 3.7\\pyetl\\Demodb0103\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Python 3.7\\pyetl\\Demodb0103\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Python 3.7\\pyetl\\Demodb0103\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Python 3.7\\pyetl\\Demodb0103\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Python 3.7\\pyetl\\Demodb0103\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Python 3.7\\pyetl\\Demodb0103\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#導入相關模組\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "\n",
    "import jieba\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#CKIPtagger導入要用的模組，分別有「WS（斷詞）」、「POS（詞性標注）」及「NER（實體辨識）」與「construct__dictionary(自建辭典)」四個功能。\n",
    "from ckiptagger import construct_dictionary, WS, POS, NER\n",
    "ws = WS('E:/Python 3.7/pyetl/Demodb0103/gym/data')\n",
    "pos = POS('E:/Python 3.7/pyetl/Demodb0103/gym/data')\n",
    "ner = NER('E:/Python 3.7/pyetl/Demodb0103/gym/data')\n",
    "\n",
    "#讀取要段詞的json檔\n",
    "DATASET_DIR = 'E:/Python 3.7/pyetl/Demodb0103/gym/data/gymz.json'\n",
    "with open(DATASET_DIR, encoding='utf8') as f:\n",
    "    dataset = json.load(f)\n",
    "    \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取停止詞典\n",
    "STOP_WORDS_DIR = 'E:/Python 3.7/pyetl/Demodb0103/gym/data/stopWords.txt'\n",
    "with open(STOP_WORDS_DIR, encoding='utf8') as f:\n",
    "    stop_words = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抽出文章的標題與內容\n",
    "content_list = list(map(lambda d: d['content'], dataset))\n",
    "title_list = list(map(lambda d: d['title'], dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#設自建辭典，並給予權重\n",
    "word_to_weight1 = {\n",
    "    \"胸肌\": 3,\n",
    "    \"胸部\": 3,\n",
    "    \"肩膀\": 3,\n",
    "    \"背肌\": 3,\n",
    "    \"背部\": 3,\n",
    "    \"手臂\": 3,\n",
    "    \"腹肌\": 3,\n",
    "    \"腹部\": 3,\n",
    "    \"核心\": 3,\n",
    "    \"腿部\": 3,\n",
    "    \"深蹲\": 3,\n",
    "    \"硬舉\": 3,\n",
    "    \"臥推\": 3,\n",
    "    \"啞鈴\": 3,\n",
    "    \"有氧運動\": 3,\n",
    "    \"徒手訓練\": 3,\n",
    "    \"徒手\": 3,\n",
    "    \"肌肉\": 3,\n",
    "    \"重訓\": 3,\n",
    "    \"健身\": 3,\n",
    "    \"弓箭步\": 3,\n",
    "    \"伏地挺身\": 3,\n",
    "    \"引體向上\": 3,\n",
    "    \"棒式\": 3,\n",
    "    \"仰臥起坐\": 3,\n",
    "    \"捲腹\": 3,\n",
    "    \"跑步\": 3,\n",
    "    \"開合跳\": 3,  \n",
    "    \"橋式\": 3,\n",
    "    \"增肌\": 2,\n",
    "    \"減脂\": 2,\n",
    "}\n",
    "dictionary1 = construct_dictionary(word_to_weight1)\n",
    "\n",
    "word_to_weight2 = {\n",
    "    \"胸\": 3,\n",
    "    \"上胸\": 2,\n",
    "    \"下胸\": 2,\n",
    "    \"肩\": 3,\n",
    "    \"手\": 3,\n",
    "    \"腿\": 3,\n",
    "    \"斜方肌\": 2,\n",
    "    \"二頭肌\": 2,\n",
    "    \"三頭肌\": 2,\n",
    "    \"小腿肌群\": 2,\n",
    "    \"臀大肌\": 2,\n",
    "    \"大腿肌\": 2,\n",
    "    \"大腿後肌\": 2,\n",
    "    \"胸大肌\": 2,\n",
    "    \"前三角\": 2,\n",
    "    \"肱三頭\": 2,\n",
    "    \"中三角\": 2,\n",
    "    \"三角肌\": 2,\n",
    "    \"後三角\": 2,\n",
    "    \"棘上肌\": 2,\n",
    "    \"小圓肌\": 2,\n",
    "    \"棘下肌\": 2,\n",
    "    \"中斜方\": 2,\n",
    "    \"菱形肌\": 2,\n",
    "    \"肱二頭\": 2,\n",
    "    \"背闊肌\": 2,\n",
    "    \"豎棘肌\": 2,\n",
    "    \"股四頭\": 2,\n",
    "    \"腿後建肌群\": 2,\n",
    "    \"核心肌群\": 3,\n",
    "    \"腿內收肌群\": 2,\n",
    "    \"臀中肌\": 2,\n",
    "    \"緋腸肌\": 2,\n",
    "    \"比目魚肌\": 2,\n",
    "    \"腹直肌\": 2,\n",
    "    \"腹橫肌\": 2,\n",
    "    \"單邊弓箭步\": 3,\n",
    "    \"上斜伏地挺身\": 3,\n",
    "    \"下斜伏地挺身\": 3,\n",
    "    \"暴力上槓\": 3,\n",
    "    \"棒式撐體\": 3,\n",
    "    \"反向捲腹\": 3,\n",
    "    \"槓鈴\": 2,\n",
    "    \"繩索\": 1,\n",
    "    \"戰神\": 1,\n",
    "    \"沙袋\": 1,\n",
    "    \"按摩池\": 1,\n",
    "    \"機械\": 1,\n",
    "    \"跑步機\": 1,\n",
    "    \"踏步機\": 1,\n",
    "    \"飛輪腳踏車\": 1,\n",
    "    \"交叉滑步訓練機\": 1,\n",
    "    \"坐姿推胸機\": 1,\n",
    "    \"肩部推舉機\": 1,\n",
    "    \"坐姿划船機\": 1,\n",
    "    \"旋轉訓練機\": 1,\n",
    "    \"臂部複合訓練機\": 1,\n",
    "    \"腿部外彎機\": 1,\n",
    "    \"腿部內彎機\": 1,\n",
    "    \"垂直蹬腿練習器\": 1,\n",
    "    \"羅馬凳\": 1,\n",
    "    \"單杠提膝器\": 1,\n",
    "    \"背肌訓練機\": 1,\n",
    "    \"心肺適能訓練\": 1,\n",
    "    \"上斜跑步機\": 1,\n",
    "    \" 跳繩\": 1,\n",
    "    \"胸推\": 1,\n",
    "    \"館長\": 1,\n",
    "    \"胸飛鳥\": 1,\n",
    "    \"上斜胸推\": 1,\n",
    "    \"上斜飛鳥\": 1,\n",
    "    \"下斜胸推\": 1,\n",
    "    \"下斜飛鳥\": 1,\n",
    "    \"肩推\": 1,\n",
    "    \"前平舉\": 1,\n",
    "    \"側平舉\": 1,\n",
    "    \"二頭彎舉\": 1,\n",
    "    \"反向飛鳥\": 1,\n",
    "    \"內旋\": 1,\n",
    "    \"外旋\": 1,\n",
    "    \"滑輪下拉\": 1,\n",
    "    \"反手\": 1,\n",
    "    \"寬握\": 1,\n",
    "    \"正常握\": 1,\n",
    "    \"窄握\": 1,\n",
    "    \"高划船\": 1,\n",
    "    \"仰臥臂屈伸\": 1,\n",
    "    \"俯身划船\": 1,\n",
    "    \"單臂划船\": 1,\n",
    "    \"單邊深蹲\": 2,\n",
    "    \"腿推\": 1,\n",
    "    \"腿伸\": 1,\n",
    "    \"腿曲\": 1,\n",
    "    \"腿內收訓練\": 1,\n",
    "    \"腿外展訓練\": 1,\n",
    "    \"臀部伸展訓練\": 1,\n",
    "    \"舉重\": 1,\n",
    "    \"組數\": 1,\n",
    "    \"次數\": 1,\n",
    "    \"節奏\": 1,\n",
    "    \"休息\": 1,\n",
    "    \"健身營養補給品\": 1,\n",
    "    \"乳清蛋白\": 1,\n",
    "    \"蛋白質營養棒\": 1,\n",
    "    \"支鏈氨基酸\": 1,\n",
    "    \"蛋白質\": 1,\n",
    "    \"碳水化合物\": 1,\n",
    "    \"鈉\": 1,\n",
    "    \"脂肪\": 1,\n",
    "    \"結實的\": 2,\n",
    "    \"身材健美的\": 2,\n",
    "    \"健康\": 1,\n",
    "    \"精實的\": 1,\n",
    "    \"肌肉拉傷\": 2,\n",
    "    \"健身狂人\": 2,\n",
    "    \"健身房會員\": 1,\n",
    "    \"隱形肥胖\": 2,\n",
    "    \"肥胖\": 2,\n",
    "    \"脂肪過量\": 2,\n",
    "    \"低體重\": 2,\n",
    "    \"標準體型\": 2,\n",
    "    \"肌肉型\": 2,\n",
    "    \"運動員型\": 2,\n",
    "    \"運動員\": 2,\n",
    "    \"低脂肪\": 2,\n",
    "    \"肘伸展\": 1,\n",
    "    \"生酮\": 1,\n",
    "}\n",
    "dictionary2 = construct_dictionary(word_to_weight2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#替換不需要的句子，並正規化\n",
    "# start = time.clock()\n",
    "gym_list =[]\n",
    "for i in content_list:\n",
    "    i = re.sub('※ 發信站: 批踢踢實業坊',' ', i)\n",
    "    i = re.sub('※ 文章網址:',' ', i)\n",
    "    i = re.sub('※ 編輯:',' ', i)\n",
    "    i = re.sub('(臺灣)',' ', i)\n",
    "    i = re.sub('來自:',' ', i)\n",
    "    #只保留中文\n",
    "    rule = re.compile(r\"[^\\u4e00-\\u9fa5]\")\n",
    "    i = rule.sub('', i)\n",
    "    gym_list.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#進行ckip中研院斷詞\n",
    "word_s = ws(gym_list,\n",
    "            #考慮分隔符\n",
    "            sentence_segmentation=True,\n",
    "            #recommend_dictionary參考詞典\n",
    "            recommend_dictionary = dictionary2,\n",
    "            #coerce_dictionary強制詞典\n",
    "            coerce_dictionary = dictionary1,\n",
    "            #斷詞參考符號\n",
    "            segment_delimiter_set={'?', '？', '!', '！', '。', ',',   \n",
    "                                   '，', ';', ':', '、'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去除停止詞\n",
    "for idx, speech in enumerate(word_s):\n",
    "    word_s[idx] = ' '.join([word for word in speech if word not in stop_words])\n",
    "# end = time.clock()\n",
    "# print('運行時間: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2Vec\n",
    "# 資料形式為一個文檔各為list元素為字串\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#全文章轉為各list包起來\n",
    "doc_clean1 = [doc.split() for doc in word_s]\n",
    "\n",
    "# 建立模型\n",
    "#window:CBOW下決定Word2Vec一次取多少詞來預測中間詞\n",
    "# size：詞向量的維度大小，維度太小會無法有效表達詞與詞的關係，維度太大會使關係太稀疏而難以找出規則\n",
    "# iter：訓練的回數，訓練過少會使得詞關係過為鬆散，訓練過度又會使得詞關係過為極端\n",
    "#min_count:出現次數大於等於min_count的詞，才會納入Word2Vec的詞典中\n",
    "#negative:Negative Sampling的取樣數量，5~20適合小數據，2~5適合大數據\n",
    "# worker=使用多核計算機進行更快的訓練\n",
    "model1 = Word2Vec(doc_clean1,window=5, negative=5,min_count=1,size=250, iter=10)\n",
    "\n",
    "# # 基於2d PCA擬合數據\n",
    "# X = model[model.wv.vocab]\n",
    "# pca = PCA(n_components=2)\n",
    "# result = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('肥吧', 0.8236936330795288),\n",
       " ('肉肉', 0.8217272758483887),\n",
       " ('瘦子', 0.8200681209564209),\n",
       " ('胖子', 0.8151029348373413),\n",
       " ('紙片人', 0.7829957604408264),\n",
       " ('瘦下來', 0.7794151306152344),\n",
       " ('瘦超多', 0.7768308520317078),\n",
       " ('從小到大', 0.7744495868682861),\n",
       " ('瘦瘦', 0.7680256962776184),\n",
       " ('變腫', 0.7654989957809448)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#顯示指定詞的關聯詞\n",
    "model1.wv.most_similar('肥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>增肌</th>\n",
       "      <th>cos</th>\n",
       "      <th>肥</th>\n",
       "      <th>cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>期</td>\n",
       "      <td>0.785412</td>\n",
       "      <td>肥吧</td>\n",
       "      <td>0.823694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>肪</td>\n",
       "      <td>0.771178</td>\n",
       "      <td>肉肉</td>\n",
       "      <td>0.821727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>減脂</td>\n",
       "      <td>0.760937</td>\n",
       "      <td>瘦子</td>\n",
       "      <td>0.820068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>增脂</td>\n",
       "      <td>0.707081</td>\n",
       "      <td>胖子</td>\n",
       "      <td>0.815103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>教會員</td>\n",
       "      <td>0.686369</td>\n",
       "      <td>紙片人</td>\n",
       "      <td>0.782996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>飽哈哈哈</td>\n",
       "      <td>0.669560</td>\n",
       "      <td>瘦下來</td>\n",
       "      <td>0.779415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>低碳日碳水</td>\n",
       "      <td>0.660588</td>\n",
       "      <td>瘦超多</td>\n",
       "      <td>0.776831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>增到</td>\n",
       "      <td>0.643537</td>\n",
       "      <td>從小到大</td>\n",
       "      <td>0.774450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>夠況且</td>\n",
       "      <td>0.638460</td>\n",
       "      <td>瘦瘦</td>\n",
       "      <td>0.768026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>掉減到</td>\n",
       "      <td>0.637703</td>\n",
       "      <td>變腫</td>\n",
       "      <td>0.765499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      增肌       cos     肥       cos\n",
       "0      期  0.785412    肥吧  0.823694\n",
       "1      肪  0.771178    肉肉  0.821727\n",
       "2     減脂  0.760937    瘦子  0.820068\n",
       "3     增脂  0.707081    胖子  0.815103\n",
       "4    教會員  0.686369   紙片人  0.782996\n",
       "5   飽哈哈哈  0.669560   瘦下來  0.779415\n",
       "6  低碳日碳水  0.660588   瘦超多  0.776831\n",
       "7     增到  0.643537  從小到大  0.774450\n",
       "8    夠況且  0.638460    瘦瘦  0.768026\n",
       "9    掉減到  0.637703    變腫  0.765499"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#顯示各個指定詞的關聯詞\n",
    "def most_similar(w2v_model, words, topn=10):\n",
    "    similar_df = pd.DataFrame()\n",
    "    for word in words:\n",
    "        try:\n",
    "            similar_words = pd.DataFrame(w2v_model.wv.most_similar(word, topn=topn), columns=[word, 'cos'])\n",
    "            similar_df = pd.concat([similar_df, similar_words], axis=1)\n",
    "        except:\n",
    "            print(word, \"not found in Word2Vec model!\")\n",
    "    return similar_df\n",
    "most_similar(model1, ['增肌', '肥'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'word2vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-265-822b3eabbe03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'增肌'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'word2vec'"
     ]
    }
   ],
   "source": [
    "# import word2vec #需要word2vec模組\n",
    "# indexes = model.cosine(u'增肌')\n",
    "# for index in indexes[0]:\n",
    "#     print (model.vocab[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext\n",
    "from gensim.models import FastText\n",
    "model2 = FastText(doc_clean1,window=5, negative=5,min_count=1,size=250, iter=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('瘦子', 0.8223647475242615),\n",
       " ('瘦胖子', 0.8076952695846558),\n",
       " ('泡芙出', 0.8064573407173157),\n",
       " ('泡芙', 0.8057920932769775),\n",
       " ('胖子', 0.8036568760871887),\n",
       " ('瘦瘦', 0.8035323023796082),\n",
       " ('紙片人', 0.7964157462120056),\n",
       " ('瘦瘦瘦', 0.796295166015625),\n",
       " ('腿頸', 0.7951831817626953),\n",
       " ('粗體型', 0.7851994633674622)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#顯示指定詞的關聯詞\n",
    "model2.wv.most_similar('肥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>增肌</th>\n",
       "      <th>cos</th>\n",
       "      <th>肥</th>\n",
       "      <th>cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>期</td>\n",
       "      <td>0.806186</td>\n",
       "      <td>瘦子</td>\n",
       "      <td>0.822365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>肪</td>\n",
       "      <td>0.771457</td>\n",
       "      <td>瘦胖子</td>\n",
       "      <td>0.807695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>減脂</td>\n",
       "      <td>0.743046</td>\n",
       "      <td>泡芙出</td>\n",
       "      <td>0.806457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>獵心喜來</td>\n",
       "      <td>0.735697</td>\n",
       "      <td>泡芙</td>\n",
       "      <td>0.805792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>增到</td>\n",
       "      <td>0.716600</td>\n",
       "      <td>胖子</td>\n",
       "      <td>0.803657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>增脂</td>\n",
       "      <td>0.687254</td>\n",
       "      <td>瘦瘦</td>\n",
       "      <td>0.803532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>試行給</td>\n",
       "      <td>0.667959</td>\n",
       "      <td>紙片人</td>\n",
       "      <td>0.796416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>補炭</td>\n",
       "      <td>0.649014</td>\n",
       "      <td>瘦瘦瘦</td>\n",
       "      <td>0.796295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>單瘦</td>\n",
       "      <td>0.646107</td>\n",
       "      <td>腿頸</td>\n",
       "      <td>0.795183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>增重</td>\n",
       "      <td>0.641037</td>\n",
       "      <td>粗體型</td>\n",
       "      <td>0.785199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     增肌       cos    肥       cos\n",
       "0     期  0.806186   瘦子  0.822365\n",
       "1     肪  0.771457  瘦胖子  0.807695\n",
       "2    減脂  0.743046  泡芙出  0.806457\n",
       "3  獵心喜來  0.735697   泡芙  0.805792\n",
       "4    增到  0.716600   胖子  0.803657\n",
       "5    增脂  0.687254   瘦瘦  0.803532\n",
       "6   試行給  0.667959  紙片人  0.796416\n",
       "7    補炭  0.649014  瘦瘦瘦  0.796295\n",
       "8    單瘦  0.646107   腿頸  0.795183\n",
       "9    增重  0.641037  粗體型  0.785199"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#顯示各個指定詞的關聯詞\n",
    "def most_similar(fas_model, words, topn=10):\n",
    "    similar_df = pd.DataFrame()\n",
    "    for word in words:\n",
    "        try:\n",
    "            similar_words = pd.DataFrame(fas_model.wv.most_similar(word, topn=topn), columns=[word, 'cos'])\n",
    "            similar_df = pd.concat([similar_df, similar_words], axis=1)\n",
    "        except:\n",
    "            print(word, \"not found in Word2Vec model!\")\n",
    "    return similar_df\n",
    "most_similar(model2, ['增肌', '肥'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
